{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Web Scraping:\n",
    "\n",
    "[web_link](https://www.ambitionbox.com/list-of-companies?page=1) `In this websites we have data of some compines. We want to fetch the data of all the compines. But this web sites does not provide us api of that sites to access data. In these we can do web scraping. And almost there is 333 pages. Fetch data from of all these pages and make a csv file.`\n",
    "\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd \n",
    "import requests\n",
    "from bs4 import BeautifulSoup # web scraping library in python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "`In web development there is a file name robots.txt file. In this file we give the name of the file that a web scraper like Google's crawler, can not scroll over my page. That's why it's showing us this kind of error. If we can undersand that we are making request from a browser then it allow us to fetch the html of the page.`\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<HTML><HEAD>\\n<TITLE>Access Denied</TITLE>\\n</HEAD><BODY>\\n<H1>Access Denied</H1>\\n \\nYou don\\'t have permission to access \"http&#58;&#47;&#47;www&#46;ambitionbox&#46;com&#47;list&#45;of&#45;companies&#63;\" on this server.<P>\\nReference&#32;&#35;18&#46;b46d3f17&#46;1719409505&#46;8aeb712\\n<P>https&#58;&#47;&#47;errors&#46;edgesuite&#46;net&#47;18&#46;b46d3f17&#46;1719409505&#46;8aeb712</P>\\n</BODY>\\n</HTML>\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.ambitionbox.com/list-of-companies?page=1'\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "# similar like json viwer we have also html viwer seach in google:\n",
    "response.text "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
